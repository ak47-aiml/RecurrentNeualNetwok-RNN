{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='steelblue'>\n",
    "\n",
    "<font size = 5>\n",
    "<b>Recurrent Neural Networks Stock Trend Prediction</b>\n",
    "  \n",
    "</font>\n",
    "\n",
    "<font color = 'grey'>\n",
    "<font size = 4>\n",
    "<br>\n",
    "    \n",
    "- Going to look at the stock price from `2005 to 2021`. Then predict the trend for\n",
    "2022, the test dataset has the data from the month of `January-October 2022`. Will compare to this test set data and see how good was our trend prediction.<br>\n",
    "    \n",
    "**Following examples are included in the processing:**\n",
    "    \n",
    "\n",
    "- `Load` training dataset\n",
    "- `Scale` the data using `MinMaxScaler`\n",
    "- `Create 60 row buckets` - approximately 3 months\n",
    "- `Use first 60 rows` are initial data (time t0)\n",
    "- `Instantiate a RNN model` - set appropriate layers\n",
    "- `Train` the model\n",
    "- `Make predictions` using test dataset\n",
    "- `Plot` trend **prediction v/s actual 2022** data\n",
    "\n",
    "</font>\n",
    "</font>\n",
    "    \n",
    "<font color = 'tomato'>\n",
    "    \n",
    "### NOT GOING TO PREDICT THE STOCK PRICE BUT PREDICT THE TREND - *UP or DOWN or FLAT*\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Activation\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data <br>\n",
    "<font size = 3>   \n",
    "Only load the training dataset, will use the test dataset for comparing the trend that is predicted\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv('../datasets/Google-Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = dataset_train.shape[0]\n",
    "print(\"number of rows: {}\".format(num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Comic sans MS; font-size:1.4em;\">   \n",
    "Only use the open price for the stock, do not need date, high, low, close values\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = dataset_train.iloc[:, 1:2].values\n",
    "training_set[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling <br>\n",
    "\n",
    "<font size = 3>   \n",
    "    \n",
    "Whenever we are going to use `sigmoid function in the RNN`, it is `recommeneded to use the MinMaxScaler` compared to the standarization scaler.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to scale between 0 and 1\n",
    "sc = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the original training set, hence create new variable\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_scaled[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Timestamp Buckets <br>\n",
    "\n",
    "<font size = 3>\n",
    "    \n",
    "- Creating a data structure with `60 timesteps and 1 output`\n",
    "- `60 timesteps` means at any time t, RNN is going to look at the `stock price of (t - 60) days`\n",
    "- And based on trend for this period, it will try to `predict the next output`\n",
    "- So `60 timesteps` is from which our `RNN is going to learn` and understand some correlations and trends and based on this understanding it  will try to `predict the output the stock price at time (t + 1)`\n",
    "- Using `1 timestep caused overfitting` and the model was not learning anything. `20 timesteps was not able to capture some trends`, then 30 and 40, the `best number of timesteps was 60`\n",
    "- `60 timesteps corresponds to 3 months` - every month has 20 financial days. We will have 60 timesteps and 1 output - stock price at (t+1)\n",
    "    \n",
    "</font>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each finnancial day - X_train will contain the 60 previous days.\n",
    "# For y_train will be output or the prediction\n",
    "X_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we want the previous 60 stock prices, we have to start at index 60 in \n",
    "# the training set i.e. 60th financial day of 2021.\n",
    "for i in range(60, num_rows):\n",
    "    # top 60 (0 - 59) will be in the first row, and 60-119 in next ....\n",
    "    # will have num_rows for X_train. Each row will have 60 columns.\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    # 60th will be in the first one, 120th in next. So will have 1198 rows and\n",
    "    # with 1 column\n",
    "    y_train.append(training_set_scaled[i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of items in list:\", len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list to numpy array as required by RNN\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping the training data<br>\n",
    "\n",
    "<font size = 3>\n",
    "    \n",
    "- Reshaping means adding more dimenonality to the dataset. This dimension we are adding is `a unit - number of predictors` we want to use to predict. Our price predictors are indicators. Here we are only using the open stock price which is our only indicator. You can have many indicators - close, volume, high, low, etc. By adding this additional  indicator, it will have predict the trend in the stock price. the `input shape has to be 3D as required by the RNN`.\n",
    "\n",
    "\n",
    "- Anytime need to add dimenion in numpy array, need to use the reshape function to do it,\n",
    "    `reshape requires 2 arguments` - what we want to reshape - `X_train and new shape our numpy array` to have. We are converting from `2D array to 3D array`. The order in which the new dimenions are to be added go to  `'keras documentation'` and look for Recurrent layers in the layers section.<br>\n",
    "    \n",
    "<ul>\n",
    "        \n",
    "<li> <b>Check the input_shape:</b> <i>3D tensor with shape - requires  (batch_size, timesteps, input_dim)</i> </li>\n",
    "<li><b>batch_size:</b> total number of rows we have in the training set (1198). </li>\n",
    "    <li><b>timesteps:</b> total number of columns for each row. </li>\n",
    "    <li><b>input_dim:</b> is the new dimension we are adding - the indicator or predictor </li>\n",
    "    <li><b>X_train.shape[0]</b> - will be number of rows, X_train.shape[1] will be number of columns</li>\n",
    "</ul>\n",
    "    \n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the RNN\n",
    "\n",
    "# regression is about predicting continous value and classificaiton is about\n",
    "# predicting a category or class.\n",
    "tf.random.set_seed(2345)\n",
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the first LSTM layer and some Dropout regularization:<br>\n",
    "<ul>\n",
    "<font size = 3>\n",
    "    <li><b>units</b> - number of LSTM cells/memory units/neurons for the LSTM layer. Even if we are going to stack the LSTM layers, we want our model to have high dimensionality. To do this we can add large number of neurons in each layer. Since predicting the stock price is complex, having a large number of neurons in each layer will help. If we had taken 3 or 5 units in each layer then the model will not be able to capture the upward and the downward trend of the stock price.</li> \n",
    "    <li><b>return_sequences</b> - since we are building a stacked LSTM, we set it to true, in the next steps we are going to add additional LSTM layers.</li>\n",
    "    <li><b>input_shape</b> - the input shape we created in the Reshaping step, a 3D array - containing the rows, columns and the indicators. In here we have to only add the last 2 dimemsions (number columns and the indicator), the first dimension will be automatically taken into account.</li> \n",
    "    \n",
    "</font>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50, return_sequences = True, \n",
    "                   input_shape = (X_train.shape[1], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dropout regularization to avoid over fitting. (20 %)\n",
    "#regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the second LSTM layer and some Dropout regularization:<br>\n",
    "\n",
    "<font size = 3>\n",
    "Adding a second LSTM layer and some Dropout regularization want to keep return_sequences to true because we are going to add more layers no need to add input_shape because we have already defined in step 1.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add LSTM layer and then drop 20% to prevent overfitting\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "#regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the third LSTM layer and some Dropout regularization:<br>\n",
    "\n",
    "<font size = 3>\n",
    "    \n",
    "Want to keep return_sequences to true because we are going to add more layers\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add LSTM Layer and then drop 20% to prevent overfitting\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "#regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the fourth and final LSTM layer and some Dropout regularization:<br>\n",
    "\n",
    "<font size = 3>\n",
    "Final layer so use default for return_sequence (set to false)\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a fourth LSTM layer and some Dropout regularization\n",
    "# final layer so use default return_sequence (set to false)\n",
    "regressor.add(LSTM(units = 50))\n",
    "#regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding output layer<br>\n",
    "\n",
    "<font size = 3>\n",
    "Have on predictor hence units = 1. Making full connection to the previous LSTM layer, use the Dense class.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get regressor summary\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# To measure time required to train\n",
    "import timeit, time\n",
    "start = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the RNN\n",
    "<ul>\n",
    "<font size = 3>\n",
    "    \n",
    "**First two arguements are X_train and y_train**\n",
    "    <li><b>epochs</b> - he number of forward and backward propagations to be done on the data. With 25 there was no convergence of loss then tried 50 - still not some convergence, then tried 100 were observed some convergence.</li> \n",
    "    <li><b>batch_size</b> - Every x times before the back propagation happens of the weights</li>\n",
    "<b>The batch_size and the epochs could be set as variables rather than hard coding them</b>\n",
    "</font>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tf.random.set_seed(2345)\n",
    "history = regressor.fit(X_train, y_train, epochs = 35, batch_size = 32, verbose = 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "stop = timeit.default_timer()\n",
    "execution_time = stop - start\n",
    "# It returns time in seconds\n",
    "exectime = time.strftime(\"%M:%S\", time.gmtime(execution_time)) \n",
    "print(\"To train it took: {} mins\".format(exectime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "plt.figure(figsize=(4,3))\n",
    "epoch = history.epoch\n",
    "plt.plot(epoch,loss);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='grey'>\n",
    "    <h2>Observe loss</h2>\n",
    "\n",
    "<font size = 3><br>\n",
    "The loss goes keeps decreasing from first epoch to last. Have prevented the over fitting enough so that the loss does not much change in the last 20 ~ 30 epochs.\n",
    "</font>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the predictions and visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the csv has the stock price for month of january 2022\n",
    "# Getting the real stock price of 2022\n",
    "dataset_test = pd.read_csv('../datasets/Google-Test.csv')\n",
    "test_rows = dataset_test.shape[0]\n",
    "print(\"number of rows in test set: {}\".format(test_rows))\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting stock price for 2022\n",
    "<ul>\n",
    "<font size = 3>\n",
    "Regressor was built using the 60 previous stock prices, to predict the 2022 stock price we will need the 60 prior days stock prices. In order to get these we will need both the training set and the test set. Some data will be from October, November and December 2021<br><br>\n",
    "We will have to do concatenation of the training set and the test set. We cannot do this since the training set is scaled whereas the test (real price) is not scaled. We do not want to scale the test set because we do not want to loose the actual values in the test set. To do this concatenation, we will use the dataset_train and dataset_test both of which have the real stock prices.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Arguments - 2 datasets that need to be concatenated and the axis along \n",
    "# which we want to concatenate - want to concatenate rows or columns.\n",
    "# axis = 0  means rows\n",
    "# dataset_train['Open'] - we are getting column named Open from the dataset.\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), \n",
    "                          axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(dataset_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are trying to get the prices using the last 3 months dec, nov, oct.\n",
    "# get to jan 3rd 2022 - len(dataset_total) - len(dataset_test)\n",
    "# to get the lower bound - subract 60 from jan 1st 2022. \n",
    "# the upper bound is the rest - the last index of the whole dataset\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "print(inputs.shape)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs is now just a numpy array of one dimension (x, ). We need to \n",
    "# transform it to have (x,1) - have one column -reshape it with values -1, 1.\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now standardize the inputs because our regressor was scaled.\n",
    "# sc was defined earlier\n",
    "inputs = sc.transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now transform it into the 3D format which we passed into the regressor.\n",
    "X_test = []\n",
    "# we have test_row entries\n",
    "for i in range(60, test_rows+60):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the 3D structure required\n",
    "#\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# predict the stock price\n",
    "predicted_stock_price = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the prediction is scaled - need to inverse transform it using\n",
    "# the scaler before it can be plotted\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real stock prices from January 2022 v/s our prediction trend\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', \n",
    "         label = 'Predicted Google Stock Price Trend')\n",
    "plt.title('Google Stock Price Prediction (2022)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
